#!/usr/bin/env python3
"""
í•œê¸€ ìˆ™ì œ ìë™ êµì • ì‹œìŠ¤í…œ v4.1
GPT-4 Vision (í…ìŠ¤íŠ¸ë§Œ) + Google Vision (ìœ„ì¹˜)

Usage:
    python3 homework-checker-v4.1.py <image_path>
"""

import sys
import json
import os
import base64
from pathlib import Path
from google.cloud import vision
from openai import OpenAI
from PIL import Image, ImageDraw, ImageFont

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.expanduser('~/.openclaw/google-vision-key.json')

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”")
    sys.exit(1)

openai_client = OpenAI(api_key=OPENAI_API_KEY)

def ocr_google_vision_with_positions(image_path):
    """Google Visionìœ¼ë¡œ ì „ì²´ í…ìŠ¤íŠ¸ + word positions"""
    client = vision.ImageAnnotatorClient()
    
    with open(image_path, 'rb') as f:
        content = f.read()
    
    image = vision.Image(content=content)
    response = client.text_detection(image=image)
    
    if response.error.message:
        raise Exception(f"Vision API Error: {response.error.message}")
    
    full_text = ""
    if response.text_annotations:
        full_text = response.text_annotations[0].description
    
    word_positions = []
    for annotation in response.text_annotations[1:]:
        vertices = annotation.bounding_poly.vertices
        x_coords = [v.x for v in vertices]
        y_coords = [v.y for v in vertices]
        
        word_positions.append({
            'text': annotation.description,
            'x': min(x_coords),
            'y': min(y_coords),
            'width': max(x_coords) - min(x_coords),
            'height': max(y_coords) - min(y_coords),
        })
    
    return full_text, word_positions

def encode_image_base64(image_path):
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode('utf-8')

def find_errors_with_gpt4v(image_path, ocr_text):
    """
    GPT-4 Visionìœ¼ë¡œ ì—ëŸ¬ "í…ìŠ¤íŠ¸"ë§Œ ì°¾ê¸° (ìœ„ì¹˜ëŠ” Google Visionì—ì„œ)
    
    Returns:
        [
            {
                "original": "ì•„ã…ìš”",
                "corrected": "ì•„íŒŒìš”",
                "type": "incomplete",
                "reasoning": "ë°›ì¹¨ì´ ëˆ„ë½ëœ ë¶ˆì™„ì „í•œ ê¸€ì"
            },
            ...
        ]
    """
    base64_image = encode_image_base64(image_path)
    
    prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì–´ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ì™¸êµ­ì¸ í•™ìƒì˜ ìˆ™ì œ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë¬¸ë²• ì˜¤ë¥˜ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

**OCR í…ìŠ¤íŠ¸ (ì°¸ê³ ìš©):**
{ocr_text[:2000]}

**ì°¾ì•„ì•¼ í•  ì˜¤ë¥˜ ìœ í˜•:**
1. **spelling** (ì² ì): "ê¸°ì¹˜"â†’"ê¸°ì¹¨", "ì£¼ì œ"â†’"ì¶•ì œ"
2. **spacing** (ë„ì–´ì“°ê¸°): "ì´ê°€ì•„íŒŒìš”"â†’"ì´ê°€ ì•„íŒŒìš”", "ëª¨ì„ì„í–ˆì–´ìš”"â†’"ëª¨ì„ì„ í–ˆì–´ìš”"
3. **incomplete** (ë¶ˆì™„ì „): "ì•„ã…ìš”"â†’"ì•„íŒŒìš”" (ë°›ì¹¨ ëˆ„ë½)
4. **verb** (ë™ì‚¬): "í•˜ì–´ìš”"â†’"í•´ìš”", "ê°€ì–´ìš”"â†’"ê°€ìš”"
5. **duplicate** (ì¤‘ë³µ): "ê°”ì–´ìš” ìˆì—ˆê² ì–´ìš”"â†’"ê°”ì–´ìš”"

**ì¤‘ìš”: ìœ„ì¹˜ ì¢Œí‘œëŠ” í•„ìš” ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë§Œ ì •í™•íˆ ì°¾ì•„ì£¼ì„¸ìš”.**

**ì¶œë ¥ í˜•ì‹ (JSON):**
```json
[
  {{
    "original": "í‹€ë¦° í…ìŠ¤íŠ¸ (ì •í™•íˆ)",
    "corrected": "ì˜¬ë°”ë¥¸ í…ìŠ¤íŠ¸",
    "type": "ì˜¤ë¥˜ ìœ í˜•",
    "reasoning": "ì™œ í‹€ë ¸ëŠ”ì§€ ì„¤ëª…"
  }}
]
```

**ì£¼ì˜ì‚¬í•­:**
- ì´ë¯¸ì§€ì—ì„œ **ì‹¤ì œë¡œ ë³´ì´ëŠ”** í•™ìƒ ì†ê¸€ì”¨ë§Œ ê²€ì‚¬
- êµì¬ ì¸ì‡„ëœ í…ìŠ¤íŠ¸ëŠ” ë¬´ì‹œ
- **original í…ìŠ¤íŠ¸ëŠ” OCR í…ìŠ¤íŠ¸ì—ì„œ ì •í™•íˆ ì°¾ì„ ìˆ˜ ìˆì–´ì•¼ í•¨**
- JSONë§Œ ì¶œë ¥ (ë‹¤ë¥¸ ì„¤ëª… ë¶ˆí•„ìš”)
"""

    response = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=2000,
        temperature=0.1,
    )
    
    result = response.choices[0].message.content.strip()
    
    # JSON ì¶”ì¶œ
    if '```json' in result:
        result = result.split('```json')[1].split('```')[0].strip()
    elif '```' in result:
        result = result.split('```')[1].split('```')[0].strip()
    
    errors = json.loads(result)
    return errors

def find_word_position(word, word_positions):
    """Google Vision word positionsì—ì„œ ë‹¨ì–´ ìœ„ì¹˜ ì°¾ê¸°"""
    # 1. ì™„ì „ ì¼ì¹˜
    for wp in word_positions:
        if word.strip() == wp['text'].strip():
            return wp
    
    # 2. ë¶€ë¶„ ì¼ì¹˜ (ë„ì–´ì“°ê¸° ì—ëŸ¬ ë“±)
    for wp in word_positions:
        if word.replace(' ', '') in wp['text'].replace(' ', ''):
            return wp
        if wp['text'].replace(' ', '') in word.replace(' ', ''):
            return wp
    
    # 3. ì²« ê¸€ìë¡œ ì¶”ì •
    if word and word_positions:
        first_char = word[0]
        for wp in word_positions:
            if wp['text'].startswith(first_char):
                return wp
    
    # 4. ì™„ì „ í¬ê¸°: ê¸°ë³¸ ìœ„ì¹˜ ë°˜í™˜
    return {'text': word, 'x': 50, 'y': 50, 'width': 100, 'height': 30}

def match_errors_with_positions(errors, word_positions):
    """GPT-4ê°€ ì°¾ì€ ì—ëŸ¬ í…ìŠ¤íŠ¸ â†’ Google Vision ìœ„ì¹˜ë¡œ ë§¤í•‘"""
    for error in errors:
        position = find_word_position(error['original'], word_positions)
        error['position'] = position
    
    return errors

def mark_homework(image_path, errors, output_path=None):
    """ë¹¨ê°„ íœ ìŠ¤íƒ€ì¼ ë§ˆí‚¹"""
    img = Image.open(image_path)
    draw = ImageDraw.Draw(img)
    
    try:
        font_correction = ImageFont.truetype("/System/Library/Fonts/Supplemental/AppleGothic.ttf", 55)
    except:
        font_correction = ImageFont.load_default()
    
    for error in errors:
        pos = error['position']
        x, y = pos['x'], pos['y']
        width, height = pos['width'], pos['height']
        
        # 1. ë¹¨ê°„ ì‚¬ì„  X
        draw.line([(x, y), (x + width, y + height)], fill="red", width=10)
        draw.line([(x + width, y), (x, y + height)], fill="red", width=10)
        
        # 2. ë¹¨ê°„ ë°‘ì¤„
        draw.line([(x, y + height + 5), (x + width, y + height + 5)], fill="red", width=12)
        
        # 3. ì •ë‹µ í…ìŠ¤íŠ¸ (ìœ„ì— ë¹¨ê°„ìƒ‰)
        correction_y = y - 60
        if correction_y < 0:
            correction_y = y + height + 20
        
        draw.text((x, correction_y), error['corrected'], fill="red", font=font_correction)
    
    if output_path is None:
        base = Path(image_path).stem
        ext = Path(image_path).suffix
        parent = Path(image_path).parent
        output_path = parent / f"{base}_v4.1_corrected{ext}"
    
    img.save(output_path)
    return str(output_path)

def evaluate_result(errors, ocr_length):
    """í‰ê°€ ì ìˆ˜ ì‚°ì¶œ"""
    score_ocr = 3.0 if ocr_length > 100 else 2.0
    
    if len(errors) == 0:
        score_grammar = 2.5
    elif len(errors) <= 2:
        score_grammar = 2.0
    elif len(errors) <= 5:
        score_grammar = 1.5
    else:
        score_grammar = 1.0
    
    score_position = 2.0
    score_usability = 1.5
    score_stability = 1.0
    
    total = score_ocr + score_grammar + score_position + score_usability + score_stability
    
    return {
        'ocr': score_ocr,
        'grammar': score_grammar,
        'position': score_position,
        'usability': score_usability,
        'stability': score_stability,
        'total': total,
        'passed': total >= 9.8,
    }

def main():
    if len(sys.argv) < 2:
        print("Usage: python3 homework-checker-v4.1.py <image_path>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    if not os.path.exists(image_path):
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {image_path}")
        sys.exit(1)
    
    print("=" * 70)
    print("ğŸ“¸ í•œê¸€ ìˆ™ì œ ìë™ êµì • v4.1 (GPT-4V + Google Vision)")
    print("=" * 70)
    print(f"ì´ë¯¸ì§€: {image_path}\n")
    
    # Step 1: Google Vision OCR + positions
    print("ğŸ” Step 1: OCR + ìœ„ì¹˜ ì¶”ì¶œ (Google Vision)...")
    ocr_text, word_positions = ocr_google_vision_with_positions(image_path)
    print(f"   âœ“ {len(ocr_text)} ê¸€ì, {len(word_positions)} ë‹¨ì–´")
    
    # Step 2: GPT-4 Visionìœ¼ë¡œ ì—ëŸ¬ í…ìŠ¤íŠ¸ ì°¾ê¸°
    print("\nğŸ¤– Step 2: ì—ëŸ¬ ê°ì§€ (GPT-4 Vision)...")
    errors = find_errors_with_gpt4v(image_path, ocr_text)
    print(f"   âœ“ {len(errors)}ê°œ ì—ëŸ¬ í…ìŠ¤íŠ¸ ë°œê²¬")
    
    # Step 3: ì—ëŸ¬ í…ìŠ¤íŠ¸ â†’ Google Vision ìœ„ì¹˜ ë§¤í•‘
    print("\nğŸ¯ Step 3: ìœ„ì¹˜ ë§¤í•‘...")
    errors = match_errors_with_positions(errors, word_positions)
    
    if errors:
        print("\nâŒ ë°œê²¬ëœ ì˜¤ë¥˜:")
        for i, error in enumerate(errors, 1):
            print(f"   {i}. '{error['original']}' â†’ '{error['corrected']}' ({error['type']})")
            print(f"      ìœ„ì¹˜: ({error['position']['x']}, {error['position']['y']})")
            print(f"      ì´ìœ : {error.get('reasoning', 'N/A')}")
    
    # Step 4: ë§ˆí‚¹
    print("\nğŸ¨ Step 4: ë¹¨ê°„ íœ ìŠ¤íƒ€ì¼ ë§ˆí‚¹...")
    output_path = mark_homework(image_path, errors)
    print(f"   âœ“ ì €ì¥: {output_path}")
    
    # í‰ê°€
    scores = evaluate_result(errors, len(ocr_text))
    
    print("\nğŸ“Š í‰ê°€:")
    print(f"   âœ“ OCR: {len(ocr_text)} ê¸€ì ({scores['ocr']:.1f}/3.0)")
    print(f"   âœ“ ë¬¸ë²•: {len(errors)}ê°œ ì˜¤ë¥˜ ({scores['grammar']:.1f}/2.5)")
    print(f"   âœ“ ìœ„ì¹˜: Google Vision ë§¤í•‘ ({scores['position']:.1f}/2.0)")
    print(f"   âœ“ ì‚¬ìš©ì„±: ì„ ìƒë‹˜ ìŠ¤íƒ€ì¼ ({scores['usability']:.1f}/1.5)")
    print(f"   âœ“ ì•ˆì •ì„±: ì •ìƒ ({scores['stability']:.1f}/1.0)")
    
    print(f"\nâ­ ì´ì : {scores['total']:.1f}/10.0")
    if scores['passed']:
        print(f"   âœ… í•©ê²© ({scores['total']:.1f})")
    else:
        print(f"   âš ï¸  ë¶ˆí•©ê²© ({scores['total']:.1f})")
    
    # JSON ì¶œë ¥
    result = {
        'status': 'success',
        'version': '4.1',
        'ocr_engine': 'google_vision',
        'error_detection': 'gpt4_vision',
        'image': image_path,
        'output': output_path,
        'errors': errors,
        'total_errors': len(errors),
        'ocr_length': len(ocr_text),
        'word_count': len(word_positions),
        'score': scores['total'],
        'passed': scores['passed'],
    }
    
    print("\n--- JSON OUTPUT ---")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == '__main__':
    main()
