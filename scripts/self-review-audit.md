# 자기평가 시스템 감사 (Self-Review System Audit)

> 날짜: 2026-02-04 15:44
> 목적: 자기평가 시스템이 실제로 작동하는지 스스로 점검

---

## 1️⃣ 기술적 실행 가능성 (Technical Feasibility)

### 1.1 Isolated 세션의 파일 쓰기 권한
**질문:** Isolated 세션에서 `memory/YYYY-MM-DD.md`에 평가를 기록할 수 있는가?

**테스트 필요:**
- [ ] exec 도구로 echo 또는 cat으로 파일에 append 가능한가?
- [ ] 파일 경로는 절대 경로? 상대 경로?
- [ ] 권한 문제는 없는가?

**리스크:** Isolated 세션이 파일 쓰기를 못 하면 평가가 공중 분해됨.

---

### 1.2 프롬프트 지시 이행률
**질문:** 크론 메시지 끝에 "자기평가 하세요"라고 써놓으면 AI가 진짜 할까?

**현실:**
- AI는 지시를 "이해"하지만 "반드시 따른다"는 보장 없음
- 긴 프롬프트 끝에 있는 지시는 무시될 가능성 높음
- 답변 생성 후 "추가 작업"을 스스로 하기는 어려움

**개선안:**
- 크론 메시지를 두 단계로 분리: (1) 답변 생성, (2) 평가 수행
- 또는 답변과 평가를 하나의 출력으로 강제

---

### 1.3 평가 누락 감지
**질문:** 크론이 평가를 안 하고 끝내면 어떻게 아는가?

**현재:** 감지 메커니즘 없음.

**개선안:**
- 평가 기록 파일에 타임스탬프 체크
- 크론 감시 리포트에서 "평가 누락" 감지
- 평가 없으면 경고 발생

---

## 2️⃣ 평가 기준의 명확성 (Criteria Clarity)

### 2.1 현재 5가지 기준 분석

| 기준 | 명확성 | 측정 가능성 | 문제점 |
|------|--------|------------|--------|
| 완성도 | ⚠️ 중간 | ❌ 어려움 | "전부 전달"의 기준이 모호. 체크리스트 필요 |
| 정확성 | ✅ 명확 | ⚠️ 중간 | 데이터 검증 방법 불명확 |
| 톤 | ❌ 모호 | ❌ 불가능 | "자비스답게 건방진가?"는 주관적 |
| 간결성 | ⚠️ 중간 | ⚠️ 중간 | 글자 수? 문장 수? 기준 없음 |
| 개선점 | ✅ 명확 | ❌ 어려움 | 주관적이지만 필요함 |

---

### 2.2 개선된 평가 기준 제안

#### A. 완성도 (Completeness) - 체크리스트화
```
[ ] 요구사항 1 전달
[ ] 요구사항 2 전달
[ ] 요구사항 3 전달
→ 3/3 = 100% 완성
```

**예: TQQQ 모니터링**
```
[ ] 현재가 ($)
[ ] 환율 (₩)
[ ] 달러 손익 (%)
[ ] 원화 손익 (%)
[ ] 전략 제안
→ 5/5 = 완성도 100%
```

---

#### B. 정확성 (Accuracy) - 검증 가능한 항목
```
[ ] 계산식 검증 (예: 수익률 = (현재가-매수가)/매수가 * 100)
[ ] 데이터 출처 명시 (예: Yahoo Finance 15분 지연)
[ ] 숫자 반올림 일관성 (예: 소수점 2자리)
→ 오류 0개 = 정확도 100%
```

---

#### C. 톤 (Tone) - 금지 표현 체크
```
❌ 금지 표현:
- "알겠습니다!", "완료!", "설정 완료!"
- "제가 도와드리겠습니다"
- "감사합니다", "좋은 하루 되세요"

✅ 자비스 표현:
- "처리했습니다."
- "끝났습니다."
- 건조한 사실 전달 + 약간의 위트
```

**측정:** 금지 표현 개수 세기 (0개 = 합격)

---

#### D. 간결성 (Conciseness) - 정량 측정
```
기준:
- 이모지 3개 이하
- 불필요한 형용사 (예: "매우", "정말", "진심으로") 사용 안 함
- 한 문장 = 한 생각 (복문 최소화)

측정:
- 이모지 수: X개 (3개 이하 = 합격)
- 불필요 단어: Y개 (0개 = 합격)
```

---

#### E. 개선점 (Improvement) - 구체성
```
❌ 나쁜 예: "더 잘하겠습니다"
✅ 좋은 예: "다음엔 환율 설명을 2줄→1줄로 압축"

기준: 구체적 액션 아이템 1개 이상
```

---

## 3️⃣ 기록 메커니즘 (Logging Mechanism)

### 3.1 현재 방식의 문제점
```
→ memory/YYYY-MM-DD.md에 평가 2-3줄 기록
```

**문제:**
1. 크론이 직접 파일을 열고 쓸 수 있나?
2. 동시 쓰기 충돌 가능성 (여러 크론이 동시 실행)
3. 파일이 없으면 생성하나? 아니면 에러?

---

### 3.2 개선안: 구조화된 평가 로그

**옵션 1: 별도 평가 전용 파일**
```
memory/self-reviews/YYYY-MM-DD.jsonl
```

**형식:**
```jsonl
{"ts":1770187440000,"cron":"TQQQ 15분 모니터링","completeness":5/5,"accuracy":"ok","tone":"ok","conciseness":"3 emojis","improvement":"환율 설명 간결화"}
```

**장점:**
- 파싱 가능 (나중에 통계 분석)
- 동시 쓰기 안전 (JSONL은 append-only)
- 크론별 추세 분석 가능

---

**옵션 2: 평가를 Discord에 전송**
```
#jarvis-reviews 채널에 자동 전송
```

**장점:**
- 파일 쓰기 필요 없음
- 정우님이 실시간 모니터링 가능
- 심각한 문제 발견 시 즉시 알림

**단점:**
- 노이즈 (14개 크론 × 하루 N회 = 많은 메시지)

---

**옵션 3: 하이브리드 (추천)**
```
1. 평가를 내부적으로 수행 (메모리)
2. 심각한 문제만 Discord #jarvis-reviews 전송
3. 일일 요약을 memory/YYYY-MM-DD.md에 기록
```

---

## 4️⃣ 강제성 (Enforcement)

### 4.1 현재: 선택적
크론이 평가를 "안 해도" 아무 문제 없음.

### 4.2 개선: 필수화

**방법 1: 프롬프트 구조 변경**
```
크론 메시지 끝에:
"답변을 생성한 후, 반드시 다음을 수행:
1. 위 답변을 5가지 기준으로 평가
2. 평가 결과를 [형식]에 맞춰 기록
3. 심각한 문제 발견 시 즉시 보고"
```

**방법 2: 2단계 크론**
```
크론 1: 답변 생성 → Discord 전송
크론 2 (1분 후): 크론 1 세션 히스토리 읽고 평가
```

**방법 3: 응답 플러그인 (after_message_sending)**
```javascript
// plugins/self-review/index.js
export async function after_message_sending(ctx, result) {
  if (ctx.sessionKind === 'cron') {
    // 크론 응답을 자동으로 평가
    const review = await evaluateResponse(ctx.message, result);
    if (review.issues.length > 0) {
      await ctx.notify(`⚠️ 자기평가 경고: ${review.issues.join(', ')}`);
    }
  }
}
```

---

## 5️⃣ 피드백 루프 (Feedback Loop)

### 5.1 현재: 일방향
```
평가 → 기록 → 끝
```

**문제:** 평가 결과를 다음 실행에 반영 안 함.

---

### 5.2 개선: 학습 루프

**Step 1: 평가 누적**
```
memory/self-reviews/TQQQ-trends.json
{
  "avg_completeness": 4.8/5,
  "common_issues": ["환율 설명 장황", "이모지 과다"],
  "improvement_rate": "+12% (최근 7일)"
}
```

**Step 2: 다음 실행 시 참고**
```
크론 메시지에 추가:
"지난 7일 평가 결과: 환율 설명이 장황했음. 이번엔 1줄로 압축."
```

**Step 3: 자동 개선**
```
"common_issues"가 3회 반복되면:
→ 크론 메시지 자체를 수정
→ 정우님께 개선안 제안
```

---

## 6️⃣ 메타 평가 (Meta-Evaluation)

### 자기평가 시스템 자체를 평가하는 기준

1. **평가 이행률** (Compliance Rate)
   - 목표: 100% (모든 크론이 매번 평가 수행)
   - 측정: `평가 기록 수 / 크론 실행 수`

2. **평가 품질** (Review Quality)
   - 목표: 구체적이고 실행 가능한 개선점 제시
   - 측정: "다음엔 XXX"와 같은 구체적 액션 아이템 비율

3. **개선 실효성** (Improvement Impact)
   - 목표: 반복 문제 감소
   - 측정: 같은 이슈가 7일 내 재발하는 비율 (목표: <20%)

4. **시스템 부담** (Overhead)
   - 목표: 평가가 크론 실행 시간을 20% 이상 늘리지 않음
   - 측정: `평가 시간 / 전체 실행 시간`

5. **신뢰도** (Reliability)
   - 목표: 평가 시스템 자체가 실패하지 않음
   - 측정: 평가 에러 발생률 (목표: <1%)

---

## 7️⃣ 실행 계획 (Action Plan)

### Phase 1: 기술 검증 (지금 당장)
- [ ] Isolated 세션에서 파일 쓰기 테스트
- [ ] 평가 기록 메커니즘 선택 (JSONL vs Discord vs Hybrid)
- [ ] 샘플 크론으로 평가 실행 테스트

### Phase 2: 기준 개선 (오늘 밤)
- [ ] 5가지 기준을 측정 가능하게 재정의
- [ ] 크론별 체크리스트 작성 (완성도 평가용)
- [ ] 금지 표현 목록 확정 (톤 평가용)

### Phase 3: 강제성 확보 (내일)
- [ ] 프롬프트 구조 변경 또는 플러그인 개발
- [ ] 평가 누락 감지 메커니즘 구현
- [ ] 크론 감시 리포트에 평가 이행률 추가

### Phase 4: 피드백 루프 (이번 주)
- [ ] 평가 트렌드 분석 스크립트 작성
- [ ] 자동 개선 제안 로직 구현
- [ ] 메타 평가 대시보드 (주간)

---

## 8️⃣ 즉시 해결 가능한 문제

### 문제 1: 파일 쓰기 불확실성
**해결:** 평가를 Discord #jarvis-reviews 채널에 전송 (파일 쓰기 우회)

### 문제 2: 평가 기준 모호함
**해결:** 각 크론별 체크리스트 작성 (완성도 측정 가능)

### 문제 3: 평가 누락 가능성
**해결:** 크론 메시지 끝에 "평가 결과를 반드시 출력하세요" 추가

### 문제 4: 피드백 루프 없음
**해결:** 주간 요약 리포트에서 평가 트렌드 분석 및 개선안 제안

---

## 9️⃣ 최종 권고사항

### 즉시 적용 (Quick Wins)
1. **평가 출력 필수화**: 크론 메시지에 "마지막에 평가 결과를 [형식]으로 출력" 추가
2. **Discord 전송**: #jarvis-reviews 채널 생성, 평가 결과 자동 전송
3. **체크리스트**: TQQQ 등 주요 크론에 완성도 체크리스트 추가

### 단기 개선 (This Week)
1. **JSONL 로그**: `memory/self-reviews/YYYY-MM-DD.jsonl` 구조화
2. **평가 누락 감지**: 크론 감시 리포트에 이행률 추가
3. **메타 평가**: 주간 요약에 평가 시스템 자체 점검 항목 추가

### 장기 비전 (Next Month)
1. **자동 개선**: 반복 문제 감지 → 크론 프롬프트 자동 수정
2. **학습 루프**: 과거 평가를 다음 실행에 반영
3. **플러그인 개발**: `after_message_sending` 훅으로 자동 평가

---

## 🎯 핵심 통찰

**자기평가 시스템이 실패하는 주된 이유:**
1. AI가 "해야 한다"는 걸 알아도 "실제로 하지 않음"
2. 평가 기준이 주관적이라 일관성 없음
3. 평가 결과를 활용하는 메커니즘 부재

**성공하려면:**
1. **강제성**: 평가 안 하면 끝나지 못하게
2. **명확성**: 체크리스트처럼 측정 가능하게
3. **피드백**: 평가가 다음 행동에 영향을 주게

---

**결론:**
현재 설계는 "좋은 의도"지만 "실행 가능성"이 낮습니다.
Phase 1부터 시작해서 점진적으로 개선이 필요합니다.
