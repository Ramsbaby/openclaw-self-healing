#!/usr/bin/env python3
"""
í•œê¸€ ìˆ™ì œ ìë™ êµì • ì‹œìŠ¤í…œ v6 (ì™„ì „ ìë™í™”)
- GPT-4o Vision: ì†ê¸€ì”¨ ì˜¤ë¥˜ ìë™ ë¶„ì„
- Google Vision OCR: ì¢Œí‘œ ì¶”ì¶œ
- ìë™ ë§¤ì¹­ + ë§ˆí‚¹

Usage:
    python3 homework-checker-v6.py <image_path>
"""

import sys
import json
import os
import base64
import re
from pathlib import Path
from openai import OpenAI
from google.cloud import vision
from PIL import Image, ImageDraw, ImageFont

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.path.expanduser('~/.openclaw/google-vision-key.json')

def analyze_with_gpt4v(image_path):
    """GPT-4o Visionìœ¼ë¡œ ì†ê¸€ì”¨ ì˜¤ë¥˜ ë¶„ì„"""
    client = OpenAI()
    
    with open(image_path, "rb") as f:
        base64_image = base64.b64encode(f.read()).decode("utf-8")
    
    # ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
    ext = Path(image_path).suffix.lower()
    media_type = "image/jpeg" if ext in [".jpg", ".jpeg"] else "image/png"
    
    prompt = """ì´ í•œêµ­ì–´ í•™ìŠµ ìˆ™ì œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ë§¤ìš° ì¤‘ìš”:**
- ì¸ì‡„ëœ í™œìì²´(êµê³¼ì„œ í…ìŠ¤íŠ¸)ëŠ” ì™„ì „íˆ ë¬´ì‹œí•˜ì„¸ìš”
- í•™ìƒì´ ì§ì ‘ ì“´ **ì†ê¸€ì”¨(í•„ê¸°ì²´)**ë§Œ ë¶„ì„í•˜ì„¸ìš”
- ì†ê¸€ì”¨ëŠ” ë³´í†µ íŒŒë€ìƒ‰/ê²€ì€ìƒ‰ ë³¼íœìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆê³ , ë¹ˆì¹¸ì´ë‚˜ í™”ì‚´í‘œ(â†’) ì˜†ì— ìˆìŠµë‹ˆë‹¤

**ì†ê¸€ì”¨ ì˜¤ë¥˜ ìœ í˜•:**
1. ë¶ˆì™„ì „í•œ ê¸€ì: ë°›ì¹¨ì´ ë¹ ì§„ ê²½ìš° (ì˜ˆ: "ì•„ã…ìš”" â†’ "ì•„íŒŒìš”", "ì•„ã… ìš”" â†’ "ì•„íŒŒìš”")
2. ë„ì–´ì“°ê¸° ì˜¤ë¥˜: ë¶™ì—¬ì“´ ê²½ìš° (ì˜ˆ: "ì´ê°€ì•„íŒŒìš”" â†’ "ì´ê°€ ì•„íŒŒìš”")
3. í™œìš©ì–´ë¯¸ ëˆ„ë½: "-ìš”"ê°€ ë¹ ì§„ ê²½ìš° (ì˜ˆ: "ì•„íŒŒ" â†’ "ì•„íŒŒìš”")
4. ì² ì ì˜¤ë¥˜

**ì´ë¯¸ì§€ êµ¬ì¡°:**
- ìƒë‹¨: "ê°€) ì´/ê°€ ì•„íŒŒìš”" ì˜†ì— í™”ì‚´í‘œ(â†’)ì™€ ì†ê¸€ì”¨ ë¬¸ì¥ë“¤
- í•˜ë‹¨: ë¹ˆì¹¸ ì±„ìš°ê¸° ë¬¸ì œì— í•™ìƒì´ ì“´ ì†ê¸€ì”¨ ë‹µ

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):
{
  "errors": [
    {
      "original": "í•™ìƒì´ ì“´ ì†ê¸€ì”¨ ê·¸ëŒ€ë¡œ",
      "corrected": "ì˜¬ë°”ë¥¸ í‘œí˜„",
      "type": "incomplete|spacing|verb|spelling",
      "location": "top|bottom",
      "search_keywords": ["ì†ê¸€ì”¨ì˜ ì²« ë‹¨ì–´"]
    }
  ]
}

location ì„¤ëª…:
- "top": ìƒë‹¨ ë¬¸ì¥ ì“°ê¸° ì˜ì—­ (â†’ í™”ì‚´í‘œ ì˜¤ë¥¸ìª½ ì†ê¸€ì”¨)
- "bottom": í•˜ë‹¨ ë¹ˆì¹¸ ì±„ìš°ê¸° ì˜ì—­ (ë¬¸ì¥ ì¤‘ê°„ ì†ê¸€ì”¨)

search_keywordsëŠ” ì†ê¸€ì”¨ì˜ **ì²« ë‹¨ì–´ë§Œ** (ì¸ì‡„ í…ìŠ¤íŠ¸ì™€ êµ¬ë¶„í•˜ê¸° ìœ„í•´):
- "ëª©ì´ ì•„ã…ìš”" â†’ ["ëª©ì´"]
- "ì´ê°€ì•„íŒŒìš”" â†’ ["ì´ê°€ì•„íŒŒìš”"] (ë¶™ì—¬ì“´ ê·¸ëŒ€ë¡œ)
- "ëª¨ì„ì„í–ˆì–´ìš”" â†’ ["ëª¨ì„ì„í–ˆì–´ìš”"] (ë¶™ì—¬ì“´ ê·¸ëŒ€ë¡œ)
"""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{media_type};base64,{base64_image}",
                            "detail": "high"
                        }
                    }
                ]
            }
        ],
        max_tokens=2000
    )
    
    result_text = response.choices[0].message.content
    
    # JSON ì¶”ì¶œ (```json ... ``` í˜•ì‹ ì²˜ë¦¬)
    json_match = re.search(r'```json\s*(.*?)\s*```', result_text, re.DOTALL)
    if json_match:
        result_text = json_match.group(1)
    
    try:
        return json.loads(result_text)
    except json.JSONDecodeError:
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
        return {"errors": [], "raw": result_text}

def ocr_with_positions(image_path):
    """Google Vision OCRë¡œ í…ìŠ¤íŠ¸ + ì¢Œí‘œ ì¶”ì¶œ"""
    client = vision.ImageAnnotatorClient()
    
    with open(image_path, 'rb') as f:
        content = f.read()
    
    image = vision.Image(content=content)
    response = client.document_text_detection(image=image)
    
    if response.error.message:
        raise Exception(f"Vision API Error: {response.error.message}")
    
    word_positions = []
    for annotation in response.text_annotations[1:]:
        vertices = annotation.bounding_poly.vertices
        x_coords = [v.x for v in vertices]
        y_coords = [v.y for v in vertices]
        word_positions.append({
            'text': annotation.description,
            'x': min(x_coords),
            'y': min(y_coords),
            'x2': max(x_coords),
            'y2': max(y_coords),
        })
    
    return word_positions

def find_error_position(error, word_positions):
    """ì˜¤ë¥˜ì˜ OCR ì¢Œí‘œ ì°¾ê¸° (location ê¸°ë°˜ í•„í„°ë§)"""
    keywords = error.get('search_keywords', [])
    location = error.get('location', '')
    
    # location ê¸°ë°˜ í•„í„°ë§
    filtered_positions = word_positions
    if location == 'top':
        # ìƒë‹¨ ì†ê¸€ì”¨: X > 1500 (â†’ í™”ì‚´í‘œ ì˜¤ë¥¸ìª½)
        filtered_positions = [wp for wp in word_positions if wp['x'] > 1500]
    elif location == 'bottom':
        # í•˜ë‹¨ ì†ê¸€ì”¨: Y > 2500 (ë¹ˆì¹¸ ì±„ìš°ê¸° ì˜ì—­)
        filtered_positions = [wp for wp in word_positions if wp['y'] > 2500]
    
    for kw in keywords:
        for wp in filtered_positions:
            if kw in wp['text'] or wp['text'] in kw:
                return wp
    
    # í‚¤ì›Œë“œë¡œ ëª» ì°¾ìœ¼ë©´ originalì—ì„œ ë‹¨ì–´ ì¶”ì¶œ
    original = error.get('original', '').replace(' ', '')
    
    for wp in filtered_positions:
        if wp['text'] in original or original in wp['text']:
            return wp
    
    # í•„í„°ë§ ì—†ì´ ì „ì²´ì—ì„œ ì°¾ê¸° (fallback)
    for kw in keywords:
        for wp in word_positions:
            if kw in wp['text'] or wp['text'] in kw:
                return wp
    
    return None

def mark_homework(image_path, errors, output_path=None):
    """ë§ˆí‚¹"""
    img = Image.open(image_path)
    draw = ImageDraw.Draw(img)
    
    # ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ í°íŠ¸ í¬ê¸° ì¡°ì •
    img_height = img.height
    font_size = max(30, img_height // 100)
    
    try:
        font = ImageFont.truetype("/System/Library/Fonts/Supplemental/AppleGothic.ttf", font_size)
    except:
        font = ImageFont.load_default()
    
    for error in errors:
        if 'position' not in error:
            continue
            
        pos = error['position']
        x, y = pos['x'], pos['y']
        x2, y2 = pos['x2'], pos['y2']
        height = y2 - y
        
        # ì·¨ì†Œì„ 
        line_y = y + height // 2
        draw.line([(x - 3, line_y), (x2 + 3, line_y)], fill="red", width=max(3, font_size // 10))
        
        # êµì • í…ìŠ¤íŠ¸
        text_bbox = draw.textbbox((0, 0), error['corrected'], font=font)
        text_w = text_bbox[2] - text_bbox[0]
        text_h = text_bbox[3] - text_bbox[1]
        
        text_x = x
        text_y = y - text_h - 8
        if text_y < 5:
            text_y = y2 + 5
        
        # í°ìƒ‰ ë°°ê²½
        pad = 3
        draw.rectangle([text_x - pad, text_y - pad, text_x + text_w + pad, text_y + text_h + pad], 
                       fill="white", outline="red", width=1)
        draw.text((text_x, text_y), error['corrected'], fill="red", font=font)
    
    if output_path is None:
        base = Path(image_path).stem
        ext = Path(image_path).suffix
        parent = Path(image_path).parent
        output_path = parent / f"{base}_v6_corrected{ext}"
    
    img.save(output_path)
    return str(output_path)

def main():
    if len(sys.argv) < 2:
        print("Usage: python3 homework-checker-v6.py <image_path>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    if not os.path.exists(image_path):
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {image_path}")
        sys.exit(1)
    
    print("=" * 60)
    print("ğŸ“¸ í•œê¸€ ìˆ™ì œ ìë™ êµì • v6 (ì™„ì „ ìë™í™”)")
    print("=" * 60)
    print(f"ì´ë¯¸ì§€: {image_path}\n")
    
    # Step 1: GPT-4o Vision ë¶„ì„
    print("ğŸ¤– Step 1: GPT-4o Vision ë¶„ì„...")
    analysis = analyze_with_gpt4v(image_path)
    errors = analysis.get('errors', [])
    print(f"   âœ“ {len(errors)}ê°œ ì˜¤ë¥˜ ê°ì§€")
    
    if errors:
        for e in errors:
            print(f"   - {e.get('original', '?')} â†’ {e.get('corrected', '?')} ({e.get('type', '?')})")
    
    # Step 2: Google Vision OCR
    print("\nğŸ” Step 2: Google Vision OCR...")
    word_positions = ocr_with_positions(image_path)
    print(f"   âœ“ {len(word_positions)} ë‹¨ì–´")
    
    # Step 3: ìœ„ì¹˜ ë§¤ì¹­
    print("\nğŸ“ Step 3: ìœ„ì¹˜ ë§¤ì¹­...")
    errors_with_pos = []
    for error in errors:
        pos = find_error_position(error, word_positions)
        if pos:
            error['position'] = pos
            errors_with_pos.append(error)
            print(f"   âœ“ {error.get('original', '?')} @ ({pos['x']}, {pos['y']})")
        else:
            print(f"   âœ— {error.get('original', '?')} ìœ„ì¹˜ ëª» ì°¾ìŒ")
    
    # Step 4: ë§ˆí‚¹
    print("\nğŸ¨ Step 4: ë§ˆí‚¹...")
    output_path = mark_homework(image_path, errors_with_pos)
    print(f"   âœ“ ì €ì¥: {output_path}")
    
    # ê²°ê³¼
    print(f"\nâœ… ì™„ë£Œ: {len(errors_with_pos)}ê°œ ì˜¤ë¥˜ ë§ˆí‚¹")
    
    result = {
        'status': 'success',
        'version': '6.0',
        'output': output_path,
        'total_errors': len(errors),
        'marked_errors': len(errors_with_pos),
        'errors': errors_with_pos,
    }
    
    print("\n--- JSON OUTPUT ---")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == '__main__':
    main()
